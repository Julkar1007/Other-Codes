{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"14Z9BrCCD966qAD6E3VqPPLxHLyqTLX95","timestamp":1743288275006},{"file_id":"1v06ciZzU5oantmESksu9P3RBI6BKHRax","timestamp":1743286885797},{"file_id":"1lUWxzZs0HIM4cxJIbdhdN63btFB4NE7E","timestamp":1743283142602}],"gpuType":"T4","authorship_tag":"ABX9TyNRSw3lVidLaqIHqKNg7L1S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":18,"metadata":{"id":"uE_7f80Vw7zo","executionInfo":{"status":"ok","timestamp":1743395755559,"user_tz":-360,"elapsed":5,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"outputs":[],"source":["import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, Trainer, TrainingArguments\n","from sklearn.model_selection import train_test_split\n","import re\n","from huggingface_hub import login\n","from transformers import TrainingArguments, Trainer"]},{"cell_type":"code","source":["# Load datasets\n","train_df = pd.read_csv('/content/Ur_train.csv')\n","test_df = pd.read_csv('/content/Ur_test_without_labels.csv')"],"metadata":{"id":"pNBZuvgRxLKk","executionInfo":{"status":"ok","timestamp":1743395755809,"user_tz":-360,"elapsed":246,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Ensure correct column names\n","train_df.columns = ['text', 'binary', 'multiclass']\n","test_df.columns = ['text']"],"metadata":{"id":"YaLf7afOxNed","executionInfo":{"status":"ok","timestamp":1743395755819,"user_tz":-360,"elapsed":10,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# Drop unnecessary columns\n","train_df = train_df.drop(columns=['multiclass'])"],"metadata":{"id":"yBdniLCkxSY0","executionInfo":{"status":"ok","timestamp":1743395755831,"user_tz":-360,"elapsed":2,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":21,"outputs":[]},{"source":["# Text Preprocessing\n","def preprocess_text(text):\n","    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n","    text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n","    text = text.lower()  # Convert to lowercase\n","    return text\n","\n","train_df['text'] = train_df['text'].apply(preprocess_text)\n","test_df['text'] = test_df['text'].apply(preprocess_text)\n","\n","# Convert labels to numeric format\n","# Replace 'Not Hope' and other non-numeric values with 0 or 1\n","train_df['binary'] = train_df['binary'].replace({'Not Hope': 0, 'Hope':1}).astype(int) # Assuming 'Hope' is the other label\n","\n","\n","# Split training data into 80% train, 20% validation\n","train_texts, val_texts, train_labels, val_labels = train_test_split(\n","    train_df['text'].tolist(), train_df['binary'].tolist(), test_size=0.2, random_state=42\n",")"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tivsiAiDxalc","executionInfo":{"status":"ok","timestamp":1743395756315,"user_tz":-360,"elapsed":483,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"9b1aa02b-d747-430a-d7eb-2aeeb002c7e7"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-22-b9cfbb733aea>:13: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  train_df['binary'] = train_df['binary'].replace({'Not Hope': 0, 'Hope':1}).astype(int) # Assuming 'Hope' is the other label\n"]}]},{"cell_type":"code","source":["# Load tokenizer\n","tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n","\n","# Tokenization\n","train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n","val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n","test_encodings = tokenizer(test_df['text'].tolist(), truncation=True, padding=True, max_length=512)"],"metadata":{"id":"YQqkOI6CxeOE","executionInfo":{"status":"ok","timestamp":1743395766858,"user_tz":-360,"elapsed":10542,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Create Dataset class\n","class TextDataset(Dataset):\n","    def __init__(self, encodings, labels=None):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.encodings['input_ids'])\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        if self.labels:\n","            item['labels'] = torch.tensor(self.labels[idx])\n","        return item"],"metadata":{"id":"PgKGQ0YtxjBL","executionInfo":{"status":"ok","timestamp":1743395766955,"user_tz":-360,"elapsed":97,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# Create dataset objects\n","train_dataset = TextDataset(train_encodings, train_labels)\n","val_dataset = TextDataset(val_encodings, val_labels)\n","test_dataset = TextDataset(test_encodings)"],"metadata":{"id":"cmplShIbxmC7","executionInfo":{"status":"ok","timestamp":1743395766969,"user_tz":-360,"elapsed":2,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n","\n","# Define local directory for saving the model\n","local_model_path = \"xlm_roberta_local\"\n","\n","# Download and save model locally\n","model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\")\n","tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")\n","\n","model.save_pretrained(local_model_path)\n","tokenizer.save_pretrained(local_model_path)\n","\n","print(f\"Model downloaded and saved to '{local_model_path}'\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uBHgY3jO4bIT","executionInfo":{"status":"ok","timestamp":1743395780510,"user_tz":-360,"elapsed":13539,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"6a5a06ed-1497-4836-8e54-d63503525731"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Model downloaded and saved to 'xlm_roberta_local'\n"]}]},{"source":["from transformers import Trainer, TrainingArguments\n","from sklearn.utils.class_weight import compute_class_weight\n","import torch\n","import numpy as np\n","#from sklearn.metrics import f1_score # Removed import\n","\n","# Removed compute_metrics function\n","#def compute_metrics(pred):\n","#    labels = pred.label_ids\n","#    preds = pred.predictions.argmax(-1)\n","#    f1 = f1_score(labels, preds, average='macro')  # Calculate macro F1 score\n","#    return {\"macro_f1\": f1}\n","\n","# Update training arguments to include compute_metrics\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    save_total_limit=2,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    logging_dir=\"./logs\",\n","    logging_strategy=\"steps\",\n","    logging_steps=10,\n","    learning_rate=2e-5,\n","    load_best_model_at_end=True,\n","    # Removed metric_for_best_model and greater_is_better\n","    #metric_for_best_model=\"macro_f1\",\n","    #greater_is_better=True,\n","    fp16=True,\n","    report_to=\"none\",\n","    # Removed compute_metrics\n","    #compute_metrics=compute_metrics\n",")"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"79CRZjS8Anby","executionInfo":{"status":"ok","timestamp":1743395806524,"user_tz":-360,"elapsed":19,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"75ffb6c4-c5a1-4368-9913-32ad6e8e4377"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}]},{"source":["# Move model to GPU if available\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model.to(device)\n","\n","# Compute class weights for handling imbalance\n","labels = train_dataset.labels\n","class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labels), y=labels)\n","class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)"],"cell_type":"code","metadata":{"id":"DGSnY2eg91Ra","executionInfo":{"status":"ok","timestamp":1743395809532,"user_tz":-360,"elapsed":362,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# Define a custom loss function with class weights\n","from torch.nn import CrossEntropyLoss\n","\n","def compute_loss(model, inputs, return_outputs=False):\n","    labels = inputs.pop(\"labels\")\n","    outputs = model(**inputs)\n","    logits = outputs.logits\n","    loss_fn = CrossEntropyLoss(weight=class_weights)  # Apply class weights here\n","    loss = loss_fn(logits, labels)\n","    return (loss, outputs) if return_outputs else loss"],"metadata":{"id":"jqbrzfbk9lVq","executionInfo":{"status":"ok","timestamp":1743395811414,"user_tz":-360,"elapsed":1,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":29,"outputs":[]},{"source":["# Define a custom training step function\n","def training_step(model, inputs, num_items_in_batch=None): # Adding num_items_in_batch argument\n","    model.train()\n","    inputs = {k: v.to(device) for k, v in inputs.items()}  # Move inputs to device\n","    # Scale the loss before backpropagation\n","    with trainer.accelerator.autocast(): # Use autocast for automatic mixed precision\n","        loss = compute_loss(model, inputs)\n","\n","    trainer.accelerator.backward(loss)  # Use accelerator for backward pass\n","    # Return loss as a Tensor instead of a float\n","    return loss.detach() # Detach to avoid retaining computational graph"],"cell_type":"code","metadata":{"id":"VcQiCfdu_BcU","executionInfo":{"status":"ok","timestamp":1743395813319,"user_tz":-360,"elapsed":4,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":30,"outputs":[]},{"source":["# Initialize Trainer without custom loss function (it's now in training_step)\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n",")\n","\n","# Override the default training step with your custom function\n","trainer.training_step = training_step"],"cell_type":"code","metadata":{"id":"vaAocs6u3fvj","executionInfo":{"status":"ok","timestamp":1743395814937,"user_tz":-360,"elapsed":18,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"BPeuao6i4-8C","executionInfo":{"status":"ok","timestamp":1743396498462,"user_tz":-360,"elapsed":678640,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"fbba4fc5-a573-4122-d86b-e03e2bb1c383"},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='693' max='693' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [693/693 11:17, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.244900</td>\n","      <td>0.214017</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.114000</td>\n","      <td>0.202471</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.131700</td>\n","      <td>0.215461</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=693, training_loss=0.2179564946743661, metrics={'train_runtime': 678.3097, 'train_samples_per_second': 16.32, 'train_steps_per_second': 1.022, 'total_flos': 2912639382835200.0, 'train_loss': 0.2179564946743661, 'epoch': 3.0})"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","# Make predictions on the validation set\n","predictions = trainer.predict(val_dataset)\n","\n","# Extract predicted labels\n","predicted_labels = predictions.predictions.argmax(-1)\n","\n","# Generate and print the classification report\n","print(classification_report(val_labels, predicted_labels))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"fqxcDfM08Zvy","executionInfo":{"status":"ok","timestamp":1743396505295,"user_tz":-360,"elapsed":6822,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"2b449669-93cc-4bab-c0fa-507b7abc30a4"},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.97      0.91      0.94       482\n","           1       0.91      0.97      0.94       441\n","\n","    accuracy                           0.94       923\n","   macro avg       0.94      0.94      0.94       923\n","weighted avg       0.94      0.94      0.94       923\n","\n"]}]},{"cell_type":"code","source":["# Predict on the test set\n","test_predictions = trainer.predict(test_dataset)\n","all_predictions = test_predictions.predictions.argmax(-1)\n","\n","# Convert numeric labels to \"Hope\" or \"Not Hope\"\n","label_mapping = {0: \"Not Hope\", 1: \"Hope\"}\n","test_df[\"Tag\"] = [label_mapping[pred] for pred in all_predictions]\n","\n","# Create submission file with \"Text\" and \"Tag\" columns\n","test_df[\"Text\"] = [\"text\" + str(i + 1) for i in range(len(test_df))]  # Generate \"text1, text2, ...\" format\n","submission_df = test_df[[\"Text\", \"Tag\"]]  # Keep only required columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"hnrxuDJoQQRZ","executionInfo":{"status":"ok","timestamp":1743396552882,"user_tz":-360,"elapsed":16317,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"79096206-b0ba-4306-f7ee-839e8bf20e18"},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}}]},{"cell_type":"code","source":["# Save as CSV\n","submission_df.to_csv(\"predictions.csv\", index=False)\n","\n","print(\"Submission file 'submission.csv' created successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QBZ_KqFIFJ7q","executionInfo":{"status":"ok","timestamp":1743396555698,"user_tz":-360,"elapsed":67,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"d633ae70-0911-4c61-8f46-c4513d490004"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Submission file 'submission.csv' created successfully!\n"]}]}]}